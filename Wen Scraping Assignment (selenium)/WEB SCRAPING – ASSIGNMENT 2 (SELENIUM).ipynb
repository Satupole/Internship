{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70cece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937511f5",
   "metadata": {},
   "source": [
    "# Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c2855171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "870f091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing browser window\n",
    "driver.maximize_window() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "154e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening naukri.com website\n",
    "url='https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "813517b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in search bar searching for Data Analyst\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "search_job.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cca80d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search job location as Bangalore\n",
    "search_job=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_job.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dffb8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "srch_btn=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "srch_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "66c747af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Looking For Immediate Joiners</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>Citiustech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Altair</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Industry X - Software Engineering</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1     Data Scientist - Looking For Immediate Joiners   \n",
       "2                   Assistant Manager - Data Science   \n",
       "3                                     Data Scientist   \n",
       "4  Python Programming Language Data Science Pract...   \n",
       "5                  Industry X - Software Engineering   \n",
       "6            Data Scientist: Artificial Intelligence   \n",
       "7  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job location       Company name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture   \n",
       "1  Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...              Wipro   \n",
       "2         Hybrid - Bangalore/Bengaluru, Mumbai, Pune         Citiustech   \n",
       "3  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...             Altair   \n",
       "4                                Bangalore/Bengaluru          Accenture   \n",
       "5                                Bangalore/Bengaluru          Accenture   \n",
       "6                                Bangalore/Bengaluru                IBM   \n",
       "7                                Bangalore/Bengaluru          Accenture   \n",
       "8                                Bangalore/Bengaluru  Applied Materials   \n",
       "9                                Bangalore/Bengaluru  Applied Materials   \n",
       "\n",
       "  Experience required  \n",
       "0             6-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             5-9 Yrs  \n",
       "3             2-7 Yrs  \n",
       "4             4-6 Yrs  \n",
       "5             3-5 Yrs  \n",
       "6             4-8 Yrs  \n",
       "7             4-6 Yrs  \n",
       "8             4-7 Yrs  \n",
       "9             4-7 Yrs  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping data in form of job title,job location,company name and experince required\n",
    "\n",
    "#creating empty list\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[] \n",
    "\n",
    "#scraping data in form of job title\n",
    "job_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "job_title\n",
    "\n",
    "#scraping data for job location    \n",
    "loc_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in loc_tag:\n",
    "    job_location.append(i.text)\n",
    "job_location\n",
    "\n",
    "#scraping data for company name    \n",
    "comp_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag:\n",
    "    company_name.append(i.text)\n",
    "company_name\n",
    "\n",
    "#scraping data for experince required    \n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 expwdth\"]')\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text) \n",
    "experience_required\n",
    "    \n",
    "#creating dataframe    \n",
    "df=pd.DataFrame({'Job Title':job_title[:10],\n",
    "                     'Job location':job_location[:10],\n",
    "                     'Company name':company_name[:10],\n",
    "                     'Experience required':experience_required[:10]})\n",
    "#printing dataframe\n",
    "df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78449d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c710f9",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6b96c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8a9d8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening naukri.com website\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4f895f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for Data Scientish in job search bar\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f76dda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for Bangalore in job search bar\n",
    "search_job=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_job.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b3dd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickinh search button\n",
    "srch_btn=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "srch_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "85760519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Looking For Immediate Joiners</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>Citiustech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Altair</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Industry X - Software Engineering</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1     Data Scientist - Looking For Immediate Joiners   \n",
       "2                   Assistant Manager - Data Science   \n",
       "3                                     Data Scientist   \n",
       "4  Python Programming Language Data Science Pract...   \n",
       "5                  Industry X - Software Engineering   \n",
       "6            Data Scientist: Artificial Intelligence   \n",
       "7  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job location       Company name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...          Accenture   \n",
       "1  Hybrid - Bangalore/Bengaluru, Hyderabad/Secund...              Wipro   \n",
       "2         Hybrid - Bangalore/Bengaluru, Mumbai, Pune         Citiustech   \n",
       "3  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...             Altair   \n",
       "4                                Bangalore/Bengaluru          Accenture   \n",
       "5                                Bangalore/Bengaluru          Accenture   \n",
       "6                                Bangalore/Bengaluru                IBM   \n",
       "7                                Bangalore/Bengaluru          Accenture   \n",
       "8                                Bangalore/Bengaluru  Applied Materials   \n",
       "9                                Bangalore/Bengaluru  Applied Materials   \n",
       "\n",
       "  Experience required  \n",
       "0             6-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             5-9 Yrs  \n",
       "3             2-7 Yrs  \n",
       "4             4-6 Yrs  \n",
       "5             3-5 Yrs  \n",
       "6             4-8 Yrs  \n",
       "7             4-6 Yrs  \n",
       "8             4-7 Yrs  \n",
       "9             4-7 Yrs  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[] \n",
    "    \n",
    "#scraping job title\n",
    "job_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "job_title\n",
    "\n",
    "#scraping job location    \n",
    "loc_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in loc_tag:\n",
    "    job_location.append(i.text)\n",
    "job_location\n",
    "\n",
    "#scraping company name   \n",
    "comp_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag:\n",
    "    company_name.append(i.text)\n",
    "company_name\n",
    "\n",
    "#scraping experience required\n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 expwdth\"]')\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text) \n",
    "experience_required\n",
    "    \n",
    "#creating dataframe with data\n",
    "df=pd.DataFrame({'Job Title':job_title[:10],\n",
    "                     'Job location':job_location[:10],\n",
    "                     'Company name':company_name[:10],\n",
    "                     'Experience required':experience_required[:10]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deceb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e47f8",
   "metadata": {},
   "source": [
    "# Q3) In this you need to scrape data as per following guidelines:                  (1) The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs (2) You have to scrape data for “Data Scientist” designation for first 10 job results. (3) You have to scrape the job-title, job-location, company name, experience required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5dbd9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7419ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening website\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "81309865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for Data Scientist in job search bar\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "87c855c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking search button\n",
    "srch_btn=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "srch_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dd0085d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting location  filter\n",
    "loc_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]')\n",
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "820335b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting salary filter\n",
    "sal_filter=loc_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "sal_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7af4b075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Chennai, Bangal...</td>\n",
       "      <td>HCLTech</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urgent hiring For Data Scientist (PHD Must Have)</td>\n",
       "      <td>Temp. WFH - Noida, Pune</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager - Data Science - Banking&amp;Financial Ser...</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Sr. Data Scientist</td>\n",
       "      <td>Temp. WFH - Noida</td>\n",
       "      <td>Wegarner Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Meon Technologies</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Alliance Recruitment Agency</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Razor Group GmbH</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                    DigitalBCG GAMMA Data Scientist   \n",
       "2   Urgent hiring For Data Scientist (PHD Must Have)   \n",
       "3  Manager - Data Science - Banking&Financial Ser...   \n",
       "4                Data Scientist / Sr. Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                             Data scientist- Python   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job location  \\\n",
       "0  Noida, Hyderabad/Secunderabad, Chennai, Bangal...   \n",
       "1                     New Delhi, Bangalore/Bengaluru   \n",
       "2                            Temp. WFH - Noida, Pune   \n",
       "3                   Delhi / NCR, Bangalore/Bengaluru   \n",
       "4                                  Temp. WFH - Noida   \n",
       "5  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "6                                              Noida   \n",
       "7                                              Noida   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                         Company name Experience required  \n",
       "0                             HCLTech             4-9 Yrs  \n",
       "1             Boston Consulting Group             2-5 Yrs  \n",
       "2                        NGI Ventures             0-4 Yrs  \n",
       "3                        Black Turtle             4-8 Yrs  \n",
       "4                  Wegarner Solutions             3-8 Yrs  \n",
       "5                torcai digital media             2-7 Yrs  \n",
       "6                   Meon Technologies             2-5 Yrs  \n",
       "7         Alliance Recruitment Agency             3-4 Yrs  \n",
       "8  TeamPlus Staffing Solution Pvt Ltd             3-6 Yrs  \n",
       "9                    Razor Group GmbH             2-3 Yrs  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[] \n",
    "\n",
    "#scraping job title\n",
    "job_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "job_title\n",
    "\n",
    "#scraping job location    \n",
    "loc_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in loc_tag:\n",
    "    job_location.append(i.text)\n",
    "job_location\n",
    "\n",
    "#scraping cpmpany name   \n",
    "comp_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag:\n",
    "    company_name.append(i.text)\n",
    "company_name\n",
    "\n",
    "#scraping experience required    \n",
    "exp_tag=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 expwdth\"]')\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text) \n",
    "experience_required\n",
    "    \n",
    "#creating dataframe with above data    \n",
    "df=pd.DataFrame({'Job Title':job_title[:10],\n",
    "                     'Job location':job_location[:10],\n",
    "                     'Company name':company_name[:10],\n",
    "                     'Experience required':experience_required[:10]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe5955",
   "metadata": {},
   "source": [
    "# Q4:Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:1. Brand  2. Product Description   3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c2d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775724e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening url\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f38162fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closimg the login page menu that pops up after opening url\n",
    "login_page=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "login_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669c3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for sunglasses in seach button\n",
    "search=driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "search.send_keys('sunglasses')\n",
    "\n",
    "#clicking seach button\n",
    "search_icon=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ba2284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "sunglasses_brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "#scraping data for sunglasses brand,their description and price for page 1\n",
    "for page in range(0,1):\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tag:\n",
    "        sunglasses_brand.append(i.text)\n",
    "\n",
    "for page in range(0,1):\n",
    "    disc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in disc_tag:\n",
    "        description.append(i.text)\n",
    "        \n",
    "for page in range(0,1):\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)        \n",
    "        \n",
    "#clicking next for page turn        \n",
    "next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_btn.click()\n",
    "time.sleep(3) #this will give time to browser to sleep until data is scraped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0818bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data for sunglasses brand,their description and price for page 2\n",
    "for page in range(1,2):\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tag:\n",
    "        sunglasses_brand.append(i.text)\n",
    "\n",
    "for page in range(1,2):\n",
    "    disc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in disc_tag:\n",
    "        description.append(i.text)\n",
    "        \n",
    "for page in range(1,2):\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "        \n",
    "#clicking next for page turn         \n",
    "next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_btn.click()\n",
    "time.sleep(3)#this will give time to browser to sleep until data is scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60af60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data for sunglasses brand,their description and price for page 2\n",
    "for page in range(2,3):\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tag:\n",
    "        sunglasses_brand.append(i.text)\n",
    "\n",
    "for page in range(2,3):\n",
    "    disc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in disc_tag:\n",
    "        description.append(i.text)\n",
    "        \n",
    "for page in range(2,3):\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa7d02ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SKYZA INDIA</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (Fr...</td>\n",
       "      <td>₹432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>Polarized Round Sunglasses (48)</td>\n",
       "      <td>₹213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (60)</td>\n",
       "      <td>₹314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand name                                Product Description Price\n",
       "0        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹649\n",
       "1          PIRASO          UV Protection Rectangular Sunglasses (52)  ₹199\n",
       "2          SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...  ₹283\n",
       "3       New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹254\n",
       "4        Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹519\n",
       "..            ...                                                ...   ...\n",
       "95    SKYZA INDIA  Polarized, UV Protection Sports Sunglasses (Fr...  ₹432\n",
       "96     PHENOMENAL  UV Protection, Mirrored Retro Square Sunglasse...  ₹369\n",
       "97      Rich Club                    Polarized Round Sunglasses (48)  ₹213\n",
       "98  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...  ₹949\n",
       "99         PIRASO           UV Protection Over-sized Sunglasses (60)  ₹314\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Brand name':sunglasses_brand[:100],'Product Description':description[:100],'Price':price[:100]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85be5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e560c6a",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 you have to scrap 3 attributes:- 1. Rating 2. Review summary 3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c5ea840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening url\n",
    "url='https://www.flipkart.com/apple-iphone-11-black-128-gb/p/itm8244e8d955aba?pid=MOBFWQ6BKRYBP5X8&lid=LSTMOBFWQ6BKRYBP5X8IBG6BS&marketplace=FLIPKART&q=iphone&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=organic&iid=5506531f-6a83-4779-9431-7a9813595e11.MOBFWQ6BKRYBP5X8.SEARCH&ppt=hp&ppn=homepage&ssid=0s59rm7sw00000001667495867942&qH=0b3f45b266a97d70'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "09de1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening show all reviews tab \n",
    "review=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div/span')\n",
    "review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cac2c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "rating=[]\n",
    "rev_sum=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "92a28efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying start and end as range for pages\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "#scrapping required of opened page and adding it in empty lists.\n",
    "for i in range(0,1):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(0,1):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(0,1):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1f5d59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[2]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7a76f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists. \n",
    "for i in range(1,2):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(1,2):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(1,2):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3dfbbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[4]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6828de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists. \n",
    "for i in range(2,3):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(2,3):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(2,3):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6144d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[5]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c7a0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists. \n",
    "for i in range(3,4):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(3,4):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(3,4):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9d907af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[6]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42e576f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(4,5):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(4,5):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(4,5):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b40c911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5cef99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(5,6):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(5,6):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(5,6):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6e51f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd83d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(6,7):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(6,7):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(6,7):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "818118da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eb6fc45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(7,8):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(7,8):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(7,8):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d87233b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "95fb3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(8,9):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(8,9):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(8,9):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "011a030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8ef0fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(9,10):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(9,10):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(9,10):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9220d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking next button to load next page\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3b99abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping required of opened page and adding it in lists\n",
    "for i in range(10,11):\n",
    "    rat_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for p in rat_tag:\n",
    "        rating.append(p.text)\n",
    "    \n",
    "for i in range(10,11):\n",
    "    rev_tag=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for p in rev_tag:\n",
    "        rev_sum.append(p.text)\n",
    "    \n",
    "for i in range(10,11):\n",
    "    rs_tag=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for p in rs_tag:\n",
    "        full_review.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "87e3d546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review summary</th>\n",
       "      <th>full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>Worst product delivered by Flipkart\\nAfter 10d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I dreamt about this day from a long time.... G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Great iphone.\\nI am writing this review after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Did an upgrade from 6s plus to iphone 11.\\nAo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>awesome Phone Smooth Touch Too good Sexyy look...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         review summary  \\\n",
       "0       5         Simply awesome   \n",
       "1       4        Value-for-money   \n",
       "2       5       Perfect product!   \n",
       "3       5    Best in the market!   \n",
       "4       5     Highly recommended   \n",
       "..    ...                    ...   \n",
       "95      5      Absolute rubbish!   \n",
       "96      5                Awesome   \n",
       "97      5              Just wow!   \n",
       "98      5                 Super!   \n",
       "99      4  Mind-blowing purchase   \n",
       "\n",
       "                                          full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   I'm Really happy with the product\\nDelivery wa...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   What a camera .....just awesome ..you can feel...  \n",
       "..                                                ...  \n",
       "95  Worst product delivered by Flipkart\\nAfter 10d...  \n",
       "96  I dreamt about this day from a long time.... G...  \n",
       "97  Great iphone.\\nI am writing this review after ...  \n",
       "98  Did an upgrade from 6s plus to iphone 11.\\nAo ...  \n",
       "99  awesome Phone Smooth Touch Too good Sexyy look...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "phone_data=pd.DataFrame({'rating':rating[:100],'review summary':rev_sum[:100],'full review':full_review[:100]})\n",
    "\n",
    "#printing dataframe\n",
    "phone_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ce59888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071691b",
   "metadata": {},
   "source": [
    "# Q6) Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:1.) Brand 2.) Product Description 3.) Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b20b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening url\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbccab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the login page menu that pops up after opening url\n",
    "login_page=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "login_page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eafc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for sneakers in search bar\n",
    "search=driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "#clicking search button \n",
    "search_icon=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da3bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "brand=[]\n",
    "for i in range(3):\n",
    "    print('scrapping page',i+1)\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for p in brand_tag:\n",
    "        brand.append(p.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f43c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Premium Sneakers For Men Sneakers For Men', 'Men’s Premium Style High Top Platform Fashion Sneakers|...', \"Perfect Stylish Casual Shoes For Girls & Women's Casual...\", 'Lightweight Pack Of 1 Trendy Sneakers Sneakers Sneakers...', 'Acrux Sneakers For Men', 'Sneakers For Men', 'Sneakers Dancing Shoes/Street Dancing Shoe For Men/R.T....', 'SS1100 Sneakers For Men', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Sneakers For Men', 'High Tops Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Lattest Sneakers Shoe Sneakers For Men', 'Premium Casual Shoes for Men Sneakers For Men', 'Outdoor Trendy Lightweight Casual,Canvas Stylish Partyw...', 'Men’s Premium Style High Top Platform Fashion Sneakers|...', 'Sneakers For Men', 'fuzor B Sneakers For Men', 'Fashionable Canvas Casual Partywear Outdoor Sneakers wh...', 'Exclusive Rap & Dance Shoes For Boys Sneakers For Men S...', 'Electron E Pro Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Sneaker Sneakers For Men', 'Sneakers For Men', \"Exclusive dancing shoe for boy's, Funky dancing sneaker...\", 'Trendy-21 White Color Change Sneakers,Casuals,Loafers S...', 'Tigonis Casuals For Men Sneakers For Men (White) Sneake...', 'Stylish Sneakers Shoes for Men Sneakers For Men', 'Sneakers For Women', '5011-Latest Collection Stylish & Trendy Casual Sneakers...', 'Combo Pack of 5 Casual Sneakers With Sneakers For Men', 'Casual Sneakers White Outdoor Shoes For Boys And Men Sn...', 'White Sneaker For Men Sneakers For Men', 'Jasper-02 Navy Casuals,Walking,Training,Running,Stylish...', 'Court Star Vulc FS Sneakers For Men', 'Premium White Casual Shoes Sneakers For Men Sneakers Fo...', 'Sneakers For Men', 'Premium Casual Shoes White Sneakers For Men']\n"
     ]
    }
   ],
   "source": [
    "print(description1[0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e7a1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n"
     ]
    }
   ],
   "source": [
    "description1=[]\n",
    "for i in range(3):\n",
    "    print('scrapping page',i+1)\n",
    "    desc_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for p in desc_tag:\n",
    "        description1.append(p.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c5e3b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n"
     ]
    }
   ],
   "source": [
    "price=[]\n",
    "for i in range(3):\n",
    "    print('scrapping page',i+1)\n",
    "    price_tag=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for p in price_tag:\n",
    "        price.append(p.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7a930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sneaker_brand</th>\n",
       "      <th>product description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Sneakers For Men Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Men’s Premium Style High Top Platform Fashion ...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Perfect Stylish Casual Shoes For Girls &amp; Women...</td>\n",
       "      <td>₹1,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Acrux Sneakers For Men</td>\n",
       "      <td>₹1,349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Exclusive Rap &amp; Dance Shoes For Boys Sneakers ...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Real Bliss</td>\n",
       "      <td>Electron E Pro Sneakers For Men</td>\n",
       "      <td>₹1,814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹3,159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneaker Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sneaker_brand                                product description   price\n",
       "0          BIRDE          Premium Sneakers For Men Sneakers For Men    ₹449\n",
       "1          BIRDE  Men’s Premium Style High Top Platform Fashion ...    ₹449\n",
       "2       RED TAPE  Perfect Stylish Casual Shoes For Girls & Women...  ₹1,249\n",
       "3         Labbin  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹395\n",
       "4       RED TAPE                             Acrux Sneakers For Men  ₹1,349\n",
       "..           ...                                                ...     ...\n",
       "95  Robbie jones  Exclusive Rap & Dance Shoes For Boys Sneakers ...    ₹349\n",
       "96    Real Bliss                    Electron E Pro Sneakers For Men  ₹1,814\n",
       "97        Kraasa                                   Sneakers For Men  ₹3,159\n",
       "98        BRUTON                                   Sneakers For Men    ₹324\n",
       "99     Deals4you                           Sneaker Sneakers For Men    ₹389\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame({'sneaker_brand':brand[:100],'product description':description1[:100],'price':price[:100]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d2bd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f10bed",
   "metadata": {},
   "source": [
    "# Q7): Go to the link - https://www.myntra.com/shoes; Set second Price filter and Color filter to “Black”and then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "62ab9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7e9821de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening url\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "504b4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting filter for black shoes only\n",
    "black_filter=driver.find_element(By.XPATH,'/html/body/div[2]/div/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "black_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "28c294e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting price bracket in price filter and selecting second option\n",
    "price_filter=driver.find_element(By.XPATH,'/html/body/div[2]/div/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "186f7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "shoe_brand=[]\n",
    "shoe_description=[]\n",
    "shoes_price=[]\n",
    "\n",
    "#scrapping data for brand,description and price for 1st page and appending in into lists.\n",
    "for i in range(0,1):\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for p in brand_tag:\n",
    "        shoe_brand.append(p.text)\n",
    "        \n",
    "    desc_tag=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for j in desc_tag:\n",
    "        shoe_description.append(j.text)\n",
    "        \n",
    "    price_tag=driver.find_elements(By.XPATH,'//span[@class=\"product-discountedPrice\"]')\n",
    "    for k in brand_tag:\n",
    "        shoes_price.append(k.text)\n",
    "    #clicking next button for next page turn\n",
    "    next_button=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "#scrapping data for brand,description and price for 2nd page and appending in into lists.\n",
    "for i in range(0,1):\n",
    "    brand_tag=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for p in brand_tag:\n",
    "        shoe_brand.append(p.text)\n",
    "        \n",
    "    desc_tag=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for j in desc_tag:\n",
    "        shoe_description.append(j.text)\n",
    "        \n",
    "    price_tag=driver.find_elements(By.XPATH,'//span[@class=\"product-discountedPrice\"]')\n",
    "    for k in brand_tag:\n",
    "        shoes_price.append(k.text)   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7ef44bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Ultraboost 5.0 DNA Running</td>\n",
       "      <td>ADIDAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>JORDAN MAX AURA 4 Shoes</td>\n",
       "      <td>Nike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR MAX DAWN Sneakers</td>\n",
       "      <td>Nike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Woven Nmd_R1 Sneakers</td>\n",
       "      <td>ADIDAS Originals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Runner Fl Running Shoes</td>\n",
       "      <td>ADIDAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Run XX Nitro Running</td>\n",
       "      <td>Puma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Textured Sneakers</td>\n",
       "      <td>ALDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Sole To Soul</td>\n",
       "      <td>Suede High-Top Block Heeled Boots</td>\n",
       "      <td>Sole To Soul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Party Block Sandals</td>\n",
       "      <td>ALDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Solid Mid-Top Boots</td>\n",
       "      <td>Saint G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand                        description             price\n",
       "0             ADIDAS     Men Ultraboost 5.0 DNA Running            ADIDAS\n",
       "1               Nike            JORDAN MAX AURA 4 Shoes              Nike\n",
       "2               Nike          Men AIR MAX DAWN Sneakers              Nike\n",
       "3   ADIDAS Originals          Men Woven Nmd_R1 Sneakers  ADIDAS Originals\n",
       "4             ADIDAS        Men Runner Fl Running Shoes            ADIDAS\n",
       "..               ...                                ...               ...\n",
       "95              Puma         Women Run XX Nitro Running              Puma\n",
       "96              ALDO            Women Textured Sneakers              ALDO\n",
       "97      Sole To Soul  Suede High-Top Block Heeled Boots      Sole To Soul\n",
       "98              ALDO          Women Party Block Sandals              ALDO\n",
       "99           Saint G          Women Solid Mid-Top Boots           Saint G\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "myntra_shoes=pd.DataFrame({'brand':shoe_brand,'description':shoe_description,'price':shoes_price})\n",
    "\n",
    "#printing dataframe\n",
    "myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d9fff0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aebb84",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/. Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” as shown in the below image:1)title,2)ratings,3)price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "30e6ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening link to scrap data\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ef61c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for laptop in search bar\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search.send_keys('laptop')\n",
    "\n",
    "#clicking search button to search data\n",
    "search_icon=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8f381334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting filter for 'processor' as 'Intel Core I7'\n",
    "cpu_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[5]/li[14]/span/a/span')\n",
    "cpu_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4b54a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "laptop_brand=[]\n",
    "ratings_star1=[]\n",
    "laptop_price1=[]\n",
    "\n",
    "#scraping laptop brands and description\n",
    "lap_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in lap_tag:\n",
    "    laptop_brand.append(i.text)\n",
    "\n",
    "#scraping laptop price    \n",
    "price_tag=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for k in price_tag:\n",
    "    laptop_price1.append(k.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "99be9912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand name with description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Pro Intel 12th Gen i7 Evo...</td>\n",
       "      <td>1,03,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>93,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>80,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) HP ProBook 430 G3 6th Gen Intel Core...</td>\n",
       "      <td>25,895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>86,956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>81,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...</td>\n",
       "      <td>1,01,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>77,500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Brand name with description     price\n",
       "0  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...    97,990\n",
       "1  Samsung Galaxy Book2 Pro Intel 12th Gen i7 Evo...  1,03,490\n",
       "2  Lenovo IdeaPad Slim 5 12th Gen Intel Core i7 1...    83,990\n",
       "3  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    93,999\n",
       "4  HP Pavilion x360 11th Gen Intel Core i7 14 inc...    80,490\n",
       "5  (Renewed) HP ProBook 430 G3 6th Gen Intel Core...    25,895\n",
       "6  Samsung Galaxy Book2 Intel 12th Gen core i7 39...    86,956\n",
       "7  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...    81,490\n",
       "8  Lenovo ThinkPad E14 Intel Core i7 12th Gen 14\"...  1,01,990\n",
       "9  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    77,500"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "laptop_data=pd.DataFrame({'Brand name with description':laptop_brand[:10],\n",
    "                          'price':laptop_price1[:10]})\n",
    "#printing dataframe\n",
    "laptop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa24567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following are some of methods i used to scrap laptop rating but could not able to scrap\n",
    "#1)\n",
    "rating=[]\n",
    "#scraping rating using relative xpath\n",
    "rat_tag=driver.find_elements('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "for i in rat_tag:\n",
    "    rating.append(i.text)\n",
    "#this code gives error:Message: invalid argument: invalid locator   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)\n",
    "rating=[]\n",
    "#scraping rating using relative xpath\n",
    "rat_tag=driver.find_elements('//*[@id=\"a-popover-content-3\"]/div/div/div/div[1]/span')\n",
    "for i in rat_tag:\n",
    "    rating.append(i.text)\n",
    "#this code gives error as:Message: invalid argument: invalid locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3381ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)\n",
    "rating=[]\n",
    "#scraping rating using absolute xpath\n",
    "rat_tag=driver.find_elements('/html/body/div[4]/div/div[1]/div/div/div/div/div[1]/span')\n",
    "for i in rat_tag:\n",
    "    rating.append(i.text)\n",
    "#this code gives error as:Message: invalid argument: invalid locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)\n",
    "rating=[]\n",
    "#scraping rating using relative xpath\n",
    "rat_tag=driver.find_elements('//i[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')\n",
    "for i in rat_tag:\n",
    "    rating.append(i.text)\n",
    "#this code gives error as:Message: invalid argument: invalid locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ee4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)\n",
    "rating=[]\n",
    "#scraping rating using relative xpath\n",
    "rat_tag=driver.find_elements('//span[@class=\"a-icon-alt\"]')\n",
    "for i in rat_tag:\n",
    "    rating.append(i.text)\n",
    "#this code gives error as:Message: invalid argument: invalid locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1abecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f70673",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.azquotes.com/\n",
    "\n",
    "2. Click on Top Quotes\n",
    "\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7a28ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening url link\n",
    "url='https://www.azquotes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1c5cbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on top quotes bar\n",
    "top_quote_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quote_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e70fc960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n",
      "scrapping page 4\n",
      "scrapping page 5\n",
      "scrapping page 6\n",
      "scrapping page 7\n",
      "scrapping page 8\n",
      "scrapping page 9\n"
     ]
    }
   ],
   "source": [
    "#creating empty list \n",
    "quotes=[]\n",
    "#scraping quotes for first 9 pages\n",
    "for i in range(9):\n",
    "    print('scrapping page',i+1)\n",
    "    quote_tag=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for p in quote_tag:\n",
    "        quotes.append(p.text)\n",
    "    \n",
    "    next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]')# clicking next button for next page to load\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "#scraping 10th page    \n",
    "for i in range(9,10):\n",
    "    quote_tag=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for p in quote_tag:\n",
    "        quotes.append(p.text)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cbeedc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking page no1 so the scraping starts from page 1 for next type of data\n",
    "reset_page_to_one=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[3]/a')\n",
    "reset_page_to_one.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d32801f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n",
      "scrapping page 4\n",
      "scrapping page 5\n",
      "scrapping page 6\n",
      "scrapping page 7\n",
      "scrapping page 8\n",
      "scrapping page 9\n"
     ]
    }
   ],
   "source": [
    "#creating empty list\n",
    "authors=[]\n",
    "#scraping data for authors for 1st 9 pages\n",
    "for i in range(9):\n",
    "    print('scrapping page',i+1)\n",
    "    author_tag=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for p in author_tag:\n",
    "        authors.append(p.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//li[@class=\"next\"]')# clicking next button for next page to load\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "#scraping 10th page \n",
    "for i in range(9,10):\n",
    "    author_tag=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for p in author_tag:\n",
    "        authors.append(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a76cea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking page no1 so the scraping starts from page 1 for next type of data\n",
    "reset_page_to_one=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[3]/a')\n",
    "reset_page_to_one.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "00158d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapping page 1\n",
      "scrapping page 2\n",
      "scrapping page 3\n",
      "scrapping page 4\n",
      "scrapping page 5\n",
      "scrapping page 6\n",
      "scrapping page 7\n",
      "scrapping page 8\n",
      "scrapping page 9\n"
     ]
    }
   ],
   "source": [
    "#creating empty list\n",
    "quote_types=[]\n",
    "#scraping data for authors for 1st 9 pages\n",
    "for i in range(9):\n",
    "    print('scrapping page',i+1)\n",
    "    type_quote_tag=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for p in type_quote_tag:\n",
    "        quote_types.append(p.text)\n",
    "    next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')#clicking next button for next page to load\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "#scraping 10th page     \n",
    "for i in range(9,10):\n",
    "    type_quote_tag=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for p in type_quote_tag:\n",
    "        quote_types.append(p.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b6b5f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quotes</th>\n",
       "      <th>author names</th>\n",
       "      <th>type of quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>No matter how plain a woman may be, if truth a...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>Beauty, Beautiful, Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quotes        author names  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  No matter how plain a woman may be, if truth a...   Eleanor Roosevelt   \n",
       "\n",
       "                                type of quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999                  Beauty, Beautiful, Truth  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "azquotes_data=pd.DataFrame({'quotes':quotes,'author names':authors,'type of quote':quote_types})\n",
    "\n",
    "#printing dataframe\n",
    "azquotes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b2c989e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36532f",
   "metadata": {},
   "source": [
    "# Q10: Write s python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "de88c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening url\n",
    "url='https://www.jagranjosh.com/.'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "eb088b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking general knowledge section\n",
    "gk_selection=driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]/a')\n",
    "gk_selection.click()\n",
    "\n",
    "#clicking on list of prime ministers of India\n",
    "list_of_PMs=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "list_of_PMs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "8d2a8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "Name=[]\n",
    "Born_dead=[]\n",
    "Term_of_office=[]\n",
    "Remarks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "40d26b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 1st prime minister and adding that data into lists\n",
    "prime_1=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[2]')\n",
    "for i in prime_1:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "99ffd7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 2nd prime minister and adding that data into lists\n",
    "prime_3=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[3]')\n",
    "for i in prime_3:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ac71c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 3rd prime minister and adding that data into lists\n",
    "prime_4=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[4]')\n",
    "for i in prime_4:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "41ae7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 4th prime minister and adding that data into lists\n",
    "prime_5=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[5]')\n",
    "for i in prime_5:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1b7d4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 5th prime minister and adding that data into lists\n",
    "prime_6=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[6]')\n",
    "for i in prime_6:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "bdbd140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 6th prime minister and adding that data into lists\n",
    "prime_7=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[7]')\n",
    "for i in prime_7:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "79b58bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 7th prime minister and adding that data into lists\n",
    "prime_8=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[8]')\n",
    "for i in prime_8:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e7a3da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 8th prime minister and adding that data into lists\n",
    "prime_9=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[9]')\n",
    "for i in prime_9:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "22c77af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 9th prime minister and adding that data into lists\n",
    "prime_10=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[10]')\n",
    "for i in prime_10:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7bc992f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 10th prime minister and adding that data into lists\n",
    "prime_11=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[11]')\n",
    "for i in prime_11:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1de1b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 11th prime minister and adding that data into lists\n",
    "prime_12=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[12]')\n",
    "for i in prime_12:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "06c8c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 12th prime minister and adding that data into lists\n",
    "prime_13=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[13]')\n",
    "for i in prime_13:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b6b3e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 13th prime minister and adding that data into lists\n",
    "prime_14=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[14]')\n",
    "for i in prime_14:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "a201e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 14th prime minister and adding that data into lists\n",
    "prime_15=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[15]')\n",
    "for i in prime_15:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "fa741a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 15th prime minister and adding that data into lists\n",
    "prime_16=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[16]')\n",
    "for i in prime_16:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "9ffb7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 16th prime minister and adding that data into lists\n",
    "prime_17=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[17]')\n",
    "for i in prime_17:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6122bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 17th prime minister and adding that data into lists\n",
    "prime_18=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[18]')\n",
    "for i in prime_18:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "07f891c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting data for 18th prime minister and adding that data into lists\n",
    "prime_19=driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[5]/span/div[2]/table/tbody/tr[19]')\n",
    "for i in prime_19:\n",
    "    Name.append(i.text.split('\\n')[1])\n",
    "    Born_dead.append(i.text.split('\\n')[2])\n",
    "    Term_of_office.append(i.text.split('\\n')[3])\n",
    "    Remarks.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "77824abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>16 years, 286 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>13 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>1 year, 216 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>13 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>11 years, 59 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>2 year, 126 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>170 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>4 years, 291 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>5 years, 32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990</td>\n",
       "      <td>343 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991</td>\n",
       "      <td>223 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996</td>\n",
       "      <td>4 years, 330 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996</td>\n",
       "      <td>16 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997</td>\n",
       "      <td>324 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998</td>\n",
       "      <td>332 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004</td>\n",
       "      <td>6 years, 64 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014</td>\n",
       "      <td>10 years, 4 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name     Born-dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                         Term of office  \\\n",
       "0         15 August 1947 to 27 May 1964   \n",
       "1           27 May 1964 to 9 June 1964,   \n",
       "2        9 June 1964 to 11 January 1966   \n",
       "3    11 January 1966 to 24 January 1966   \n",
       "4      24 January 1966 to 24 March 1977   \n",
       "5       24 March 1977 to  28 July 1979    \n",
       "6       28 July 1979 to 14 January 1980   \n",
       "7    14 January 1980 to 31 October 1984   \n",
       "8    31 October 1984 to 2 December 1989   \n",
       "9   2 December 1989 to 10 November 1990   \n",
       "10     10 November 1990 to 21 June 1991   \n",
       "11          21 June 1991 to 16 May 1996   \n",
       "12           16 May 1996 to 1 June 1996   \n",
       "13         1 June 1996 to 21 April 1997   \n",
       "14      21 April 1997 to 19 March 1998    \n",
       "15        19 March 1998 to 22 May 2004    \n",
       "16        22 May 2004 to 26 May 2014      \n",
       "17                26 May 2014 - Present   \n",
       "\n",
       "                                              Remarks  \n",
       "0                                  16 years, 286 days  \n",
       "1                                             13 days  \n",
       "2                                    1 year, 216 days  \n",
       "3                                             13 days  \n",
       "4                                   11 years, 59 days  \n",
       "5                                    2 year, 126 days  \n",
       "6                                            170 days  \n",
       "7                                   4 years, 291 days  \n",
       "8                                    5 years, 32 days  \n",
       "9                                            343 days  \n",
       "10                                           223 days  \n",
       "11                                  4 years, 330 days  \n",
       "12                                            16 days  \n",
       "13                                           324 days  \n",
       "14                                           332 days  \n",
       "15                                   6 years, 64 days  \n",
       "16                                   10 years, 4 days  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "prime=pd.DataFrame({'Name':Name,'Born-dead':Born_dead,'Term of office':Term_of_office,'Remarks':Remarks})\n",
    "#printing dataframe\n",
    "prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "61fd209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e083736",
   "metadata": {},
   "source": [
    "# Q11:Write s python program to display list of 50 Most expensive cars in the world (i.e. Company name, Model name and Price) from https://www.motor1.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "5e76133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to driver\n",
    "driver=webdriver.Chrome(r'D:\\softwares\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "#opening link\n",
    "url='https://www.motor1.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "95da47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking dropdown button \n",
    "dropdown_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div[1]/div')\n",
    "dropdown_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "446d6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting 'LISTS' option\n",
    "list_selection=driver.find_element(By.XPATH,'/html/body/div[3]/div[1]/div[3]/ul/li[4]/a')\n",
    "list_selection.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "24d25a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting and clicking '50 most expensive cars in the option' option\n",
    "selecting_data=driver.find_element(By.XPATH,'/html/body/div[2]/div[9]/div[1]/div[1]/div/div/div[1]/div/div[1]/h3/a')\n",
    "selecting_data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "f6d44226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "car_brand_and_model=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "0f7365aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping car brand and model\n",
    "car_tag=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in car_tag:\n",
    "    car_brand_and_model.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "44907d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping car prices for 1st 10 cars\n",
    "price1=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[4]')\n",
    "for i in price1:\n",
    "    price.append(i.text)\n",
    "price_tag2=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[6]')\n",
    "for i in price_tag2:\n",
    "    price.append(i.text)\n",
    "price_tag3=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[8]')\n",
    "for i in price_tag3:\n",
    "    price.append(i.text)    \n",
    "price_tag4=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[10]')\n",
    "for i in price_tag4:\n",
    "    price.append(i.text)\n",
    "price_tag5=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[12]')\n",
    "for i in price_tag5:\n",
    "    price.append(i.text)\n",
    "price_tag6=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[14]')\n",
    "for i in price_tag6:\n",
    "    price.append(i.text)\n",
    "price_tag7=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[16]')\n",
    "for i in price_tag7:\n",
    "    price.append(i.text)    \n",
    "price_tag8=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[18]')\n",
    "for i in price_tag8:\n",
    "    price.append(i.text)\n",
    "price_tag9=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[20]')\n",
    "for i in price_tag9:\n",
    "    price.append(i.text)\n",
    "price_tag10=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[22]')\n",
    "for i in price_tag10:\n",
    "    price.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "fe4dd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping car prices for next 10 cars\n",
    "price11=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[24]')\n",
    "for i in price11:\n",
    "    price.append(i.text)\n",
    "price_tag12=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[26]')\n",
    "for i in price_tag12:\n",
    "    price.append(i.text)\n",
    "price_tag13=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[28]')\n",
    "for i in price_tag13:\n",
    "    price.append(i.text)    \n",
    "price_tag14=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[30]')\n",
    "for i in price_tag14:\n",
    "    price.append(i.text)\n",
    "price_tag5=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[32]')\n",
    "for i in price_tag5:\n",
    "    price.append(i.text)\n",
    "price_tag6=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[34]')\n",
    "for i in price_tag6:\n",
    "    price.append(i.text)\n",
    "price_tag7=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[36]')\n",
    "for i in price_tag7:\n",
    "    price.append(i.text)    \n",
    "price_tag8=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[38]')\n",
    "for i in price_tag8:\n",
    "    price.append(i.text)\n",
    "price_tag9=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[40]')\n",
    "for i in price_tag9:\n",
    "    price.append(i.text)\n",
    "price_tag10=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[42]')\n",
    "for i in price_tag10:\n",
    "    price.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "adf6f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping car prices for next 10 cars\n",
    "price1=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[44]')\n",
    "for i in price1:\n",
    "    price.append(i.text)\n",
    "price_tag2=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[46]')\n",
    "for i in price_tag2:\n",
    "    price.append(i.text)\n",
    "price_tag3=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[48]')\n",
    "for i in price_tag3:\n",
    "    price.append(i.text)    \n",
    "price_tag4=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[50]')\n",
    "for i in price_tag4:\n",
    "    price.append(i.text)\n",
    "price_tag5=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[52]')\n",
    "for i in price_tag5:\n",
    "    price.append(i.text)\n",
    "price_tag6=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[54]')\n",
    "for i in price_tag6:\n",
    "    price.append(i.text)\n",
    "price_tag7=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[56]')\n",
    "for i in price_tag7:\n",
    "    price.append(i.text)    \n",
    "price_tag8=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[58]')\n",
    "for i in price_tag8:\n",
    "    price.append(i.text)\n",
    "price_tag9=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[60]')\n",
    "for i in price_tag9:\n",
    "    price.append(i.text)\n",
    "price_tag10=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[62]')\n",
    "for i in price_tag10:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "d4a07769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping car prices for next 10 cars\n",
    "price1=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[64]')\n",
    "for i in price1:\n",
    "    price.append(i.text)\n",
    "price_tag2=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[66]')\n",
    "for i in price_tag2:\n",
    "    price.append(i.text)\n",
    "price_tag3=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[68]')\n",
    "for i in price_tag3:\n",
    "    price.append(i.text)    \n",
    "price_tag4=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[70]')\n",
    "for i in price_tag4:\n",
    "    price.append(i.text)\n",
    "price_tag5=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[72]')\n",
    "for i in price_tag5:\n",
    "    price.append(i.text)\n",
    "price_tag6=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[74]')\n",
    "for i in price_tag6:\n",
    "    price.append(i.text)\n",
    "price_tag7=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[76]')\n",
    "for i in price_tag7:\n",
    "    price.append(i.text)    \n",
    "price_tag8=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[78]')\n",
    "for i in price_tag8:\n",
    "    price.append(i.text)\n",
    "price_tag9=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[80]')\n",
    "for i in price_tag9:\n",
    "    price.append(i.text)\n",
    "price_tag10=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[82]')\n",
    "for i in price_tag10:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "1a216df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping car prices for last 10 cars\n",
    "price1=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[84]')\n",
    "for i in price1:\n",
    "    price.append(i.text)\n",
    "price_tag2=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[86]')\n",
    "for i in price_tag2:\n",
    "    price.append(i.text)\n",
    "price_tag3=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[88]')\n",
    "for i in price_tag3:\n",
    "    price.append(i.text)    \n",
    "price_tag4=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[90]')\n",
    "for i in price_tag4:\n",
    "    price.append(i.text)\n",
    "price_tag5=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[92]')\n",
    "for i in price_tag5:\n",
    "    price.append(i.text)\n",
    "price_tag6=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[94]')\n",
    "for i in price_tag6:\n",
    "    price.append(i.text)\n",
    "price_tag7=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[96]')\n",
    "for i in price_tag7:\n",
    "    price.append(i.text)    \n",
    "price_tag8=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[98]')\n",
    "for i in price_tag8:\n",
    "    price.append(i.text)\n",
    "price_tag9=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[100]')\n",
    "for i in price_tag9:\n",
    "    price.append(i.text)\n",
    "price_tag10=driver.find_elements(By.XPATH,'//*[@id=\"article_box\"]/div[1]/div[2]/div[1]/p[102]')\n",
    "for i in price_tag10:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e3ed3941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car name and model</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drako GTE</td>\n",
       "      <td>Price: $1.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 car name and model                        price\n",
       "0                         Drako GTE          Price: $1.2 Million\n",
       "1                     De Tomaso P72          Price: $1.3 Million\n",
       "2                 Ferrari LaFerrari          Price: $1.4 Million\n",
       "3                     Pagani Huayra          Price: $1.4 Million\n",
       "4                      McLaren Elva          Price: $1.7 Million\n",
       "5                       Czinger 21C          Price: $1.7 Million\n",
       "6                     Ferrari Monza          Price: $1.7 Million\n",
       "7                Gordon Murray T.33          Price: $1.7 Million\n",
       "8                 Koenigsegg Gemera          Price: $1.7 Million\n",
       "9                       Zenvo TSR-S          Price: $1.7 Million\n",
       "10               Hennessey Venom F5          Price: $1.8 Million\n",
       "11                  Bentley Bacalar          Price: $1.9 Million\n",
       "12    Hispano Suiza Carmen Boulogne          Price: $1.9 Million\n",
       "13           Bentley Mulliner Batur          Price: $2.0 Million\n",
       "14                     Deus Vayanne          Price: $2.0 Million\n",
       "15                      SSC Tuatara         Price: $2.0 Million*\n",
       "16                      Lotus Evija          Price: $2.1 Million\n",
       "17              Aston Martin Vulcan          Price: $2.3 Million\n",
       "18                       Delage D12          Price: $2.3 Million\n",
       "19                McLaren Speedtail          Price: $2.3 Million\n",
       "20                     Rimac Nevera          Price: $2.4 Million\n",
       "21                    Pagani Utopia          Price: $2.5 Million\n",
       "22             Pininfarina Battista          Price: $2.5 Million\n",
       "23                Ferrari FXX K Evo          Price: $2.6 Million\n",
       "24               Gordon Murray T.50          Price: $2.6 Million\n",
       "25             Lamborghini Countach          Price: $2.6 Million\n",
       "26         Mercedes-AMG Project One          Price: $2.7 Million\n",
       "27              Aston Martin Victor          Price: $3.0 Million\n",
       "28      Hennessey Venom F5 Roadster                 $3.0 Million\n",
       "29                 Koenigsegg Jesko          Price: $3.0 Million\n",
       "30            Aston Martin Valkyrie          Price: $3.2 Million\n",
       "31        W Motors Lykan Hypersport          Price: $3.4 Million\n",
       "32                    McLaren Solus                 $3.5 Million\n",
       "33        Pagani Huayra Roadster BC          Price: $3.5 Million\n",
       "34         Bugatti Chiron Pur Sport          Price: $3.6 Million\n",
       "35                 Lamborghini Sian          Price: $3.6 million\n",
       "36                 Koenigsegg CC850          Price: $3.7 Million\n",
       "37  Bugatti Chiron Super Sport 300+          Price: $3.9 Million\n",
       "38               Lamborghini Veneno          Price: $4.5 Million\n",
       "39                   Bugatti Bolide          Price: $4.7 Million\n",
       "40                  Bugatti Mistral          Price: $5.0 Million\n",
       "41              Pagani Huayra Imola          Price: $5.4 Million\n",
       "42                     Bugatti Divo          Price: $5.8 Million\n",
       "43              SP Automotive Chaos          Price: $6.4 Million\n",
       "44                 Pagani Codalunga          Price: $7.4 Million\n",
       "45         Mercedes-Maybach Exelero          Price: $8.0 Million\n",
       "46               Bugatti Centodieci          Price: $9.0 Million\n",
       "47             Rolls-Royce Sweptail         Price: $12.8 Million\n",
       "48         Bugatti La Voiture Noire         Price: $13.4 Million\n",
       "49           Rolls-Royce Boat Tail*  Price: $28.0 Million (est.)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe\n",
    "car_data=pd.DataFrame({'car name and model':car_brand_and_model[:50],\n",
    "                       'price':price})\n",
    "#printing dataframe\n",
    "car_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close() #closing driver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
